{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Basics Of Mobile Robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "A common pathfinding algorithm in computer science and artificial intelligence is the A* (A-star) algorithm. Its purpose is to determine the shortest path on a graph or grid between a starting point and a goal point. Combining the ideas of Greedy Best-First Search and Dijkstra's algorithm, A* uses a heuristic function to effectively direct the search.\n",
    "\n",
    "Important attributes:\n",
    "\n",
    "Optimality: If certain requirements are satisfied, A* ensures that the shortest path will be found. \n",
    "\n",
    "Heuristic Guidance: A* estimates the cost from the current node to the goal using a heuristic function, commonly referred to as the \"h-value\". By directing the search, this heuristic increases algorithmic efficiency by examining the most promising paths first.\n",
    "\n",
    "Various methods can be employed to apply the A* algorithm on a map, including the fixed-grid size approach, Voronoi diagrams, visibility graphs, and cell decomposition methods. Each method offers distinct advantages and considerations for pathfinding applications.\n",
    "\n",
    "In our project, we assessed two primary pathfinding approaches: the fixed-grid size method and the visibility graph. Although the visibility graph demonstrated a slightly faster computation time, the difference was not substantial. However, a critical drawback surfaced with the visibility graph method, as it significantly reduced the number of reachable points, resulting in suboptimal solutions.\n",
    "\n",
    "You can see our visibility graph below: \n",
    "\n",
    "<img src=\"images\\vis_graph.jpeg\" alt=\"Visibility Graph\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "Given that computation time differences were marginal, we decided to favor the fixed-grid size approach. This method involves dividing the map into uniform squares of predetermined cell sizes and utilizing obstacle masks generated through computer vision to construct a grid. The A* algorithm is then applied to this grid to determine the most efficient path.\n",
    "\n",
    "We are displaying the A* exploration in real time, and an screenshot of such display can be seen below:\n",
    "\n",
    "<img src=\"images\\Astar_explore.png\" alt=\"Exploration\" style=\"width: 500px;\"/>\n",
    "\n",
    "We are also displaying the grid and the found path on the the map. You can see the screenshot of them below:\n",
    "\n",
    "<img src=\"images\\Astar_path.png\" alt=\"Path\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import heapq\n",
    "import timeit\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from computer_vision import * \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# possible moves from one square to another\n",
    "moves_8n = [(0, -1), (0, 1), (-1, 0), (1, 0), (-1, -1), (-1, 1), (1, -1), (1, 1)]\n",
    "\n",
    "moves_4n = [(0, -1), (0, 1), (-1, 0), (1, 0)]\n",
    "\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Represents a node in the A* algorithm.\n",
    "\n",
    "    Attributes:\n",
    "    - parent (Node): The parent node in the search tree.\n",
    "    - position (Tuple[int, int]): The position (coordinates) of the node on the grid.\n",
    "    - cost_of_move (float): The cost of reaching this node from the start.\n",
    "    - heuristic (float): The estimated cost to reach the goal from this node.\n",
    "    - total_cost (float): The sum of the cost_of_move and heuristic.\n",
    "\n",
    "    Methods:\n",
    "    - __eq__(self, other): Compares two nodes based on their positions.\n",
    "    - __lt__(self, other): Compares two nodes based on their total_cost \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, parent=None, position=None):\n",
    "\n",
    "        self.parent = parent\n",
    "        self.position = position\n",
    "\n",
    "        self.cost_of_move = 0\n",
    "\n",
    "        self.heuristic = 0\n",
    "        self.total_cost = 0\n",
    "\n",
    "\n",
    "    def __eq__(self, other):\n",
    "\n",
    "        return self.position == other.position\n",
    "\n",
    "\n",
    "    def __lt__(self, other):\n",
    "\n",
    "        if self.total_cost == other.total_cost:\n",
    "\n",
    "            return id(self) < id(other)\n",
    "\n",
    "        return self.total_cost < other.total_cost\n",
    "\n",
    "\n",
    "def astar_grid(maze, start, end, moves, map_copy):\n",
    "    \"\"\"\n",
    "    A* search algorithm for finding the shortest path on a 2D grid.\n",
    "\n",
    "    Parameters:\n",
    "    - maze (numpy.ndarray): A 2D grid where 0 represents an open path, and 1 represents an obstacle.\n",
    "    - start (Tuple[int, int]): The starting point on the grid.\n",
    "    - end (Tuple[int, int]): The destination point on the grid.\n",
    "    - moves (List[Tuple[int, int]]): A list of tuples representing possible moves from a given position.\n",
    "\n",
    "    Returns:\n",
    "    - np.array[Tuple[int, int]] or None: The shortest path from the start to the end on the grid, or None if no path is found.\n",
    "\n",
    "    Node Class:\n",
    "    - The algorithm uses a Node class to represent a point in the search space, which includes information about the node's position,\n",
    "      cost of movement from the start, heuristic (estimated cost to reach the goal), and the total cost.\n",
    "\n",
    "    Assumptions:\n",
    "    - The maze is represented as a NumPy array where 0 denotes an open path, and 1 denotes an obstacle.\n",
    "\n",
    "    Example:\n",
    "    >>> maze = np.array([[0, 0, 0, 1, 0],\n",
    "    ...                  [0, 1, 0, 1, 0],\n",
    "    ...                  [0, 1, 0, 0, 0],\n",
    "    ...                  [0, 0, 0, 1, 0],\n",
    "    ...                  [0, 0, 0, 0, 0]])\n",
    "    >>> start = (0, 0)\n",
    "    >>> end = (4, 4)\n",
    "    >>> moves_8n = [(1, 0), (-1, 0), (0, 1), (0, -1), (1, 1), (-1, -1), (-1, 1), (1, -1)]\n",
    "    >>> path = astar_grid(maze, start, end, moves_8n)\n",
    "    \"\"\"\n",
    "\n",
    "    start_node = Node(None, start)\n",
    "\n",
    "    start_node.cost_of_move = start_node.heuristic = start_node.total_cost = 0\n",
    "\n",
    "    end_node = Node(None, end)\n",
    "\n",
    "    end_node.cost_of_move = end_node.heuristic = end_node.total_cost = 0\n",
    "\n",
    "    open_list = []\n",
    "    closed_set = set()\n",
    "    visited_positions = set()  # Maintain a set of visited positions\n",
    "\n",
    "    heapq.heappush(open_list, start_node)\n",
    "    visited_positions.add(start)\n",
    "\n",
    "    while open_list:\n",
    "\n",
    "        current_node = heapq.heappop(open_list)\n",
    "\n",
    "        closed_set.add(current_node.position)\n",
    "\n",
    "        cv2.circle(map_copy, (int((current_node.position[0] * map_copy.shape[1]) / len(maze[0])),\n",
    "                              int((current_node.position[1] * map_copy.shape[0]) / len(maze))), 2, (125, 0, 55), -1)\n",
    "        cv2.imshow('Map_copy', map_copy)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        if current_node == end_node:\n",
    "            path = []\n",
    "            while current_node:\n",
    "                path.append(current_node.position)\n",
    "\n",
    "                current_node = current_node.parent\n",
    "\n",
    "            return path[::-1]\n",
    "\n",
    "        children = [\n",
    "            Node(current_node, (current_node.position[0] + dx, current_node.position[1] + dy))\n",
    "\n",
    "            for dx, dy in moves\n",
    "            if (\n",
    "\n",
    "                    0 <= current_node.position[0] + dx < len(maze[0])\n",
    "\n",
    "                    and 0 <= current_node.position[1] + dy < len(maze)\n",
    "\n",
    "                    and maze[current_node.position[1] + dy][current_node.position[0] + dx] == 0\n",
    "\n",
    "                    and (current_node.position[0] + dx, current_node.position[1] + dy) not in closed_set\n",
    "                    and (current_node.position[0] + dx, current_node.position[1] + dy) not in visited_positions\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        for child in children:\n",
    "\n",
    "            dx, dy = child.position[0] - current_node.position[0], child.position[1] - current_node.position[1]\n",
    "\n",
    "            child.cost_of_move = current_node.cost_of_move + 1.41 if dx != 0 and dy != 0 else current_node.cost_of_move + 1\n",
    "\n",
    "            child.heuristic = np.sqrt(abs(child.position[0] - end_node.position[0])**2 \\\n",
    "                              + abs(child.position[1] - end_node.position[1])**2)\n",
    "\n",
    "            child.total_cost = child.cost_of_move + child.heuristic\n",
    "\n",
    "            heapq.heappush(open_list, child)\n",
    "            visited_positions.add(child.position)\n",
    "\n",
    "\n",
    "\n",
    "def simplify_path(path):\n",
    "\n",
    "    \"\"\"\n",
    "    Simplifies a path by removing unnecessary intermediate points.\n",
    "\n",
    "    Parameters:\n",
    "    - path (np.array[Tuple[int, int]]): The original path represented as a list of coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - np.array[Tuple[int, int]]: The simplified path with unnecessary intermediate points removed.\n",
    "    \n",
    "    Example:\n",
    "    >>> simplify_path([(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2)])\n",
    "    [(0, 0), (3, 0), (3, 2)]\n",
    "\n",
    "    \"\"\"\n",
    "    simplified_path = [path[0]] \n",
    "\n",
    "    for i in range(1, len(path) - 1):\n",
    "        current_point = np.array(path[i])\n",
    "        next_point = np.array(path[i + 1])\n",
    "        direction_vector = next_point - np.array(simplified_path[-1])\n",
    "        \n",
    "        if np.cross(direction_vector, current_point - np.array(simplified_path[-1])) == 0:\n",
    "            continue  \n",
    "\n",
    "        simplified_path.append(path[i]) \n",
    "\n",
    "    simplified_path.append(path[-1])\n",
    "\n",
    "    return simplified_path\n",
    "\n",
    "def make_path(map_img, obstacle_masks, cell_size, start, end, grid,  metric_padding, map_x = 600, map_y = 400):\n",
    "    \"\"\"\n",
    "    Generates a path on a grid-based map using A* algorithm, considering obstacles on the image.\n",
    "\n",
    "    Parameters:\n",
    "    - map_img (numpy.ndarray): The original map image.\n",
    "    - obstacle_masks (List[numpy.ndarray]): List of obstacle masks on the map.\n",
    "    - cell_size (int): Size of each grid cell.\n",
    "    - start (Tuple[int, int]): Starting point in image coordinates (x, y).\n",
    "    - end (Tuple[int, int]): Ending point in image coordinates (x, y).\n",
    "    - grid (numpy.ndarray): The grid representing the map.\n",
    "    - map_x (int): Width of the map in image coordinates.\n",
    "    - map_y (int): Height of the map in image coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[numpy.ndarray, List[Tuple[int, int]], List[Tuple[int, int]], List[Tuple[float, float]]]:\n",
    "        - grid (numpy.ndarray): The grid with obstacle information.\n",
    "        - path_grid (List[Tuple[int, int]]): The path on the grid coordinates.\n",
    "        - simplified_path (List[Tuple[int, int]]): The simplified path on the grid coordinates.\n",
    "        - metric_path (List[Tuple[float, float]]): The path in metric (image) coordinates.\n",
    "\n",
    "    Example:\n",
    "    >>> map_img = cv2.imread('map_image.png')\n",
    "    >>> obstacle_masks = [obstacle_mask_1, obstacle_mask_2]\n",
    "    >>> cell_size = 10\n",
    "    >>> start = (100, 50)\n",
    "    >>> end = (300, 200)\n",
    "    >>> grid, path_grid, simplified_path, metric_path = make_path(map_img, obstacle_masks, cell_size, start, end, grid)\n",
    "    \"\"\"\n",
    "    map_copy = map_img.copy()\n",
    "    bw_map = cv2.cvtColor(map_img.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    grid = create_grid(bw_map, obstacle_masks, cell_size, metric_padding)\n",
    "    start_grid = (grid.shape[1] * start[0] // map_img.shape[1], grid.shape[0] * start[1] // map_img.shape[0])\n",
    "    end_grid = (grid.shape[1] * end[0] // map_img.shape[1], grid.shape[0] * end[1] // map_img.shape[0])\n",
    "    path_grid = astar_grid(grid, start_grid, end_grid, moves_8n, map_copy)\n",
    "    \n",
    "    if path_grid is None:\n",
    "        print(\"no path found\")\n",
    "        return grid, None, None, None\n",
    "    simplified_path = simplify_path(path_grid)\n",
    "    metric_path = transform_grid_to_metric(simplified_path, map_x, map_y, grid)\n",
    "\n",
    "    return grid, path_grid, simplified_path, metric_path, map_copy \n",
    "\n",
    "\n",
    "def transform_grid_to_metric(path, map_width, map_height, grid):\n",
    "    \"\"\"\n",
    "    Transforms a path from grid coordinates to metric (image) coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - path (List[Tuple[int, int]]): The path in grid coordinates.\n",
    "    - map_width (int): Width of the map in metric (image) coordinates.\n",
    "    - map_height (int): Height of the map in metric (image) coordinates.\n",
    "    - grid (numpy.ndarray): The grid representing the map.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple[float, float]]: The path in metric (image) coordinates.\n",
    "\n",
    "    Example:\n",
    "    >>> path = [(0, 0), (3, 0), (3, 2)]\n",
    "    >>> map_width = 600\n",
    "    >>> map_height = 400\n",
    "    >>> grid = np.zeros((4, 4), dtype=int)\n",
    "    >>> metric_path = transform_grid_to_metric(path, map_width, map_height, grid)\n",
    "    \"\"\"\n",
    "    metric_path = []\n",
    "    grid_x = grid.shape[1]\n",
    "    grid_y = grid.shape[0]\n",
    "    for x,y in path:\n",
    "        metric_path.append(((x * map_width) / grid_x, (y * map_height) / grid_y))\n",
    "\n",
    "    return metric_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Filter\n",
    "This section has been written and the code made by Jean Cordonnier\n",
    "## Introduction\n",
    "We decided to go with a kalman filter as our bayesian filter. Our choice has been made based on 2 factors: it does not take big computational power (like the particle filter) and we assumed gaussian noise on the system. To implement the filter we used a python library from GitHub : https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/. The installation is in requirement.txt. \n",
    "\n",
    "To deal with the non-linearities in the orientation and position (we needed to change frame using the angle of the robot for the acceleration ad the velocity) and to deal with the format of the measurement (position ,velocity and acceleration being 2 dimensions variables and heading and spin (dheading/dt) being one dimensionnal) we decided to go with two kalmans: One for the position and one for the orientation. We will refer to them as kf_pos and kf_rot. Both are implemented in a kalman class defined in kalman.py\n",
    "## Kalman for Position implementation\n",
    "### Choice for measurement and state variables\n",
    "For our measurements we used the data from the accelerometers, the average of the velocity of the wheels and the position from the camera. \n",
    "The kalman coordinates are exprimed in the local frame (with 0,0 being the top left corner) and the velocity and the accelerometers were exprimed in the body frame (centered with the robot) we had to do a coordinate change represented by this function: \n",
    "```python\n",
    "#Change from body frame to local frame\n",
    "def change_frame(body_data,body_orientation):\n",
    "    '''\n",
    "    Change from body frame to local frame.\n",
    "\n",
    "    Parameters:\n",
    "    - body_data: Data expressed in the body frame.\n",
    "    - body_orientation: Orientation of the robot in the local frame (from kf_rot).\n",
    "\n",
    "    Returns:\n",
    "    Data expressed in the local frame.\n",
    "    '''\n",
    "    R = np.array([[np.cos(body_orientation), -np.sin(body_orientation)],\n",
    "                  [np.sin(body_orientation), np.cos(body_orientation)]])\n",
    "    accel_local = R.dot(body_data)\n",
    "    return accel_local\n",
    "```\n",
    "The kf_pos has the following state variables (in the local frame): [positionx, positiony, velocityx, velocityy, accelerationx, accelerationy]. We also needed to define the F matrix linking the previous state to the next state such that x_next = F*x_previous. We defined it based on simple movement equation. Since the measurements dont have the same refresh rate we have to update the F matrix at every iteration depending on dt. \n",
    "```python\n",
    "self.kf_pos.F = np.array([[1,0,dt,0,0.5*dt**2,0],\n",
    "                          [0,1,0,dt,0,0.5*dt**2],\n",
    "                          [0,0,1,0,dt,0],\n",
    "                          [0,0,0,1,0,dt],\n",
    "                          [0,0,0,0,1,0],\n",
    "                          [0,0,0,0,0,1]])\n",
    "```\n",
    "One of the challenge we had to face was to manage to give the measurements with different frequencies. The solution we chose was to declare only two measurement in the declaration of the function and adapt the H matrix (linking the measurement z and the state x such that z = H*x) depending on which type of measurement it was. Which gave those results: \n",
    "```python\n",
    "#for the acceleration\n",
    "self.kf_pos.H = np.array([[0,0,0,0,1,0],\n",
    "                         [0,0,0,0,0,1]])\n",
    "                         #for the acceleration\n",
    "self.kf_pos.H = np.array([[0,0,1,0,0,0],\n",
    "                         [0,0,0,1,0,0]])\n",
    "#for the acceleration\n",
    "self.kf_pos.H = np.array([[1,0,0,0,0,0],\n",
    "                         [0,1,0,0,0,0]])\n",
    "```\n",
    "\n",
    "The other challenge was to compute the process noise matrix Q. We assumed the noises to be independent so the non-diagonal terms had to be zero. For the diagonal terms we found our answer here: https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/07-Kalman-Filter-Math.ipynb. We don't really understand the 'why' of the math behind it but the kalman converged with this Q matrix so we are happy with it (and it did not work with other tries)\n",
    "The final implementation of the Q matrix was this: \n",
    "```python\n",
    "#compute Q according to dt \n",
    "        self.kf_pos.Q = np.array([\n",
    "        [1/4 * noise**2 * dt**4, 0, 0, 0, 0, 0],\n",
    "        [0, 1/4 * noise**2 * dt**4, 0, 0, 0, 0],\n",
    "        [0, 0, noise**2 * dt**2, 0, 0, 0],\n",
    "        [0, 0, 0, noise**2 * dt**2, 0, 0],\n",
    "        [0, 0, 0, 0, noise**2, 0],\n",
    "        [0, 0, 0, 0, 0, noise**2]])\n",
    "```\n",
    "In the end we had to compute the noise of each measurement. We assumed it to be white noise for all measurement and to be equivalent for the x and y part. The process to calculate the noise will be detailled below. For the implementation of the measurement noise matrix we used diagonal matrix with the covariance of the measurement: \n",
    "\n",
    "```python\n",
    "#for acceleration\n",
    "self.kf_pos.R = (self.ACCEL_NOISE**2)*np.eye(2)\n",
    "#for velocity\n",
    "self.kf_pos.R = (self.VEL_NOISE**2)*np.eye(2)\n",
    "#for position\n",
    "self.kf_pos.R = (self.POS_NOISE**2)*np.eye(2)\n",
    "```\n",
    "We also had to initalize our start variable and the trust we have in it and then we were good to go! Our kalman loop looks like this (here for the acceleration measurement only but the idea doesnt change for others measurements)\n",
    "```python \n",
    "#call this line when you want to update the accelerometer measurement\n",
    "kf_pos.update_acceleration([accx,accy],current_time)\n",
    "\n",
    "def update_acceleration(self,data,time):\n",
    "    \n",
    "        # calculate time since last measurement and update it\n",
    "        dt = time- self.time_pos\n",
    "        self.time_pos = time\n",
    "\n",
    "        #get current rotation from other kalman\n",
    "        rotation = self.kf_rot.x.T[0]\n",
    "\n",
    "        # Transform body frame to local frame\n",
    "        data = change_frame(data, rotation)\n",
    "\n",
    "        # Save measurement for plotting\n",
    "        self.accel_measurement.append(data)\n",
    "\n",
    "        # Update kf parameters to accept accel measurement\n",
    "        self.kf_pos.H = np.array([[0,0,0,0,1,0],\n",
    "                                  [0,0,0,0,0,1]])\n",
    "        self.kf_pos.R = (self.ACCEL_NOISE**2)*np.eye(2)\n",
    "\n",
    "        #Update kalman\n",
    "        self._compute_kf_pos(data,dt)\n",
    "\n",
    "\n",
    "# Same for velocity, position and acceleration measurement\n",
    "# Update the F matrix, Q matrix and update the measurement for the position kalman\n",
    "def _compute_kf_pos(self,data, dt):\n",
    "\n",
    "    # get accel_noise for process noise matrix\n",
    "    noise = self.ACCEL_NOISE # most dominant noise\n",
    "\n",
    "    # compute F according to dt\n",
    "    self.kf_pos.F = np.array([[1,0,dt,0,0.5*dt**2,0],\n",
    "                    [0,1,0,dt,0,0.5*dt**2],\n",
    "                    [0,0,1,0,dt,0],\n",
    "                    [0,0,0,1,0,dt],\n",
    "                    [0,0,0,0,1,0],\n",
    "                    [0,0,0,0,0,1]])\n",
    "    \n",
    "    # compute Q according to dt \n",
    "    self.kf_pos.Q = np.array([\n",
    "    [1/4 * noise**2 * dt**4, 0, 0, 0, 0, 0],\n",
    "    [0, 1/4 * noise**2 * dt**4, 0, 0, 0, 0],\n",
    "    [0, 0, noise**2 * dt**2, 0, 0, 0],\n",
    "    [0, 0, 0, noise**2 * dt**2, 0, 0],\n",
    "    [0, 0, 0, 0, noise**2, 0],\n",
    "    [0, 0, 0, 0, 0, noise**2]])\n",
    "\n",
    "    #predict and update kalman\n",
    "    self.kf_pos.predict()\n",
    "    self.kf_pos.update(data)\n",
    "```\n",
    "## Kalman for rotation \n",
    "\n",
    "The kalman for rotation is very similar to the kf_pos except that the measurements differ ( and there is not any frame change). We used as state variable (and measurement also) the heading (from the camera) and the heading rate change (from the wheel speed difference). As the implementation is easier than kf_pos we will not review his full implementation as we can just adapt the steps presented above. \n",
    "\n",
    "## Noise processing and data acquisition\n",
    "\n",
    "For the noise calculation and the measurement equivalence we did the following: \n",
    "Position x and position y : Measurement: from the camera. Noise: make the robot stand still with the camera looking at it. Save the camera measurements of the position and extract the covariance. \n",
    "Velocity x and Velocity y : Measurement: fix identique speed for both wheel. Measure the time to cover a known distance and deduce a linear speed for all motor input. Always output the average of the two wheels and make it go through the rotation matrix. Noise: We fine tuned it using the position from the camera as a ground truth\n",
    "Acceleration x and acceleration y: Measurement: from the accelerometer, we changed the value taking the gravity as a reference. Npise: as the accelerometer were giving stable values when the thymio was stopped we use the 9.81/21(equivalent of gravity for accelerometer) as a value. We increased it by 10 later on since it seemed very inaccurate (accelerometers were not precise enough)\n",
    "Heading change (spin): Measurement: from the wheel. We gave an opposite speed to the 2 wheels than we calculated the time to make 10 turn around itself and calculated the spin in rad/s. From this we computed a linear relation between the spin and the wheel speed difference. Noise: We fined tuned it using the heading from the camera as a ground truth.\n",
    "Heading: Measurement: from the camera. Noise: make the robot stand still with the camera looking at it. Save the camera measurements of the heading and extract the covariance.\n",
    "\n",
    "In the end our noises were declared in the kalman class with those values:\n",
    "\n",
    "``` python\n",
    " ACCEL_NOISE = 10*9.81/23\n",
    "VEL_NOISE = 0.001\n",
    "ROT_NOISE = 0.005\n",
    "POS_NOISE = 0.005\n",
    "SPIN_NOISE = 0.1\n",
    "```\n",
    "\n",
    "\n",
    "## Simulation of the kalman\n",
    "\n",
    "All the simulation of the kalman have been made in kalman.ipynb. We created artificial sensor data and we added white noise to it. We also tested the class we create in test_kalman_class.ipynb (but note that since the noise value are not accurate the result don't fit the curve perfectly but it still is a good example on how to use the Kalman class with rotation and acceleration data). In kalman.ipynb we simulated acceleration measurement and position measurement then stopped position measurement to only rely on accelerometer data. All measurements are in local frame.\n",
    "\n",
    "\n",
    "<img src=\"images/kalman_simulation_position.png\" alt=\"Results for the position, the initial position starts at (25,0)\" width=\"400\"/>\n",
    "\n",
    "Legend: Results for the position, the initial position starts at (25,0). We can see that despite having no GPS data the position estimation fits really well the ground truth but drift slowly away from it. The estimation converges quite quickly to the ground truth position in the beginning\n",
    "\n",
    "<img src=\"images/kalman_simulation_speed.png\" alt=\"Results for the speed\" width=\"400\"/>\n",
    "\n",
    "Legend: Results for the speed. We can see that it matches the ground truth but it takes somes times to converge when the speed changes. \n",
    "\n",
    "<img src=\"images/kalman_simulation_acceleration.png\" alt=\"Results for the acceleration\" width=\"400\"/>\n",
    "\n",
    "Legend: Results for the acceleration. We can see that we start hitting the limit of the kalman since the shift becomes more important. The results are still accurate\n",
    "\n",
    "\n",
    "## Real application of the kalman\n",
    "\n",
    "Now it was time to test our kalman in the robot. We made the robot follow a path, hid the camera for a bit and saw what is gave us. It is important to notice that make the robot working with bluetooth and the sensor values were a bit shifted over time. \n",
    "\n",
    "<img src=\"images/Kalman_setup.png\" alt=\"Kalman results\" width=\"400\"/>\n",
    "\n",
    "Legend: Picture of the kalman path\n",
    "\n",
    "<img src=\"images/Kalman_position.png\" alt=\"Kalman results\" width=\"1100\"/>\n",
    "\n",
    "Legend: Kalman position vs Camera measurement. The robot starts on the bottom left. We can see that the kalman estimates the path perfectly when there is camera measurement. When there is no camera we can see that the inertial navigation does the job even though it drifts a little over time. The results tend to differ from one try to another (espcially when it is connected via cable or bluetooth). In general, the inertial navigation allows the thymio to go across the whole board (long side) with 2-3 turn with a +- good approximation on the position. \n",
    "\n",
    "<img src=\"images/Kalman_graph.png\" alt=\"Kalman results\" width=\"1100\"/>\n",
    "\n",
    "Legend: Kalman state variable vs Measured one. In general we can see that we have a good fit between the data measurement and estimation. We have a big shift between the kalman and the camera heading. We think part of it is due to the bluetooth connection as it diseappars whith a wired connection. Also the initial position are not saved so there is one point missing for the kalman wich can explain part of the shift. We can see that we can only rely on inertial navigation the kalman data tends to match more the sensors data.\n",
    "\n",
    "\n",
    "## Kalman Conclusion\n",
    "\n",
    "Globally we are happy with the kalman results as it allows us to perform robust localisation and inertial navigation to a certain extend. We think that using an extended KF could have helped us get better results that converges more easily. We would say that the filtering part is successful\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start the client and wait for a lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
