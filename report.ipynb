{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Basics Of Mobile Robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Filter\n",
    "This section has been written and the code made by Jean Cordonnier\n",
    "## Introduction\n",
    "We decided to go with a kalman filter as our bayesian filter. Our choice has been made based on 2 factors: it does not take big computational power (like the particle filter) and we assumed gaussian noise on the system. To implement the filter we used a python library from GitHub : https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/. The installation is in requirement.txt. \n",
    "\n",
    "To deal with the non-linearities in the orientation and position (we needed to change frame using the angle of the robot for the acceleration ad the velocity) and to deal with the format of the measurement (position ,velocity and acceleration being 2 dimensions variables and heading and spin (dheading/dt) being one dimensionnal) we decided to go with two kalmans: One for the position and one for the orientation. We will refer to them as kf_pos and kf_rot. Both are implemented in a kalman class defined in kalman.py\n",
    "## Kalman for Position implementation\n",
    "### Choice for measurement and state variables\n",
    "For our measurements we used the data from the accelerometers, the average of the velocity of the wheels and the position from the camera. \n",
    "The kalman coordinates are exprimed in the local frame (with 0,0 being the top left corner) and the velocity and the accelerometers were exprimed in the body frame (centered with the robot) we had to do a coordinate change represented by this function: \n",
    "```python\n",
    "#Change from body frame to local frame\n",
    "def change_frame(body_data,body_orientation):\n",
    "    '''\n",
    "    Change from body frame to local frame.\n",
    "\n",
    "    Parameters:\n",
    "    - body_data: Data expressed in the body frame.\n",
    "    - body_orientation: Orientation of the robot in the local frame (from kf_rot).\n",
    "\n",
    "    Returns:\n",
    "    Data expressed in the local frame.\n",
    "    '''\n",
    "    R = np.array([[np.cos(body_orientation), -np.sin(body_orientation)],\n",
    "                  [np.sin(body_orientation), np.cos(body_orientation)]])\n",
    "    accel_local = R.dot(body_data)\n",
    "    return accel_local\n",
    "```\n",
    "The kf_pos has the following state variables (in the local frame): [positionx, positiony, velocityx, velocityy, accelerationx, accelerationy]. We also needed to define the F matrix linking the previous state to the next state such that x_next = F*x_previous. We defined it based on simple movement equation. Since the measurements dont have the same refresh rate we have to update the F matrix at every iteration depending on dt. \n",
    "```python\n",
    "self.kf_pos.F = np.array([[1,0,dt,0,0.5*dt**2,0],\n",
    "                          [0,1,0,dt,0,0.5*dt**2],\n",
    "                          [0,0,1,0,dt,0],\n",
    "                          [0,0,0,1,0,dt],\n",
    "                          [0,0,0,0,1,0],\n",
    "                          [0,0,0,0,0,1]])\n",
    "```\n",
    "One of the challenge we had to face was to manage to give the measurements with different frequencies. The solution we chose was to declare only two measurement in the declaration of the function and adapt the H matrix (linking the measurement z and the state x such that z = H*x) depending on which type of measurement it was. Which gave those results: \n",
    "```python\n",
    "#for the acceleration\n",
    "self.kf_pos.H = np.array([[0,0,0,0,1,0],\n",
    "                         [0,0,0,0,0,1]])\n",
    "                         #for the acceleration\n",
    "self.kf_pos.H = np.array([[0,0,1,0,0,0],\n",
    "                         [0,0,0,1,0,0]])\n",
    "#for the acceleration\n",
    "self.kf_pos.H = np.array([[1,0,0,0,0,0],\n",
    "                         [0,1,0,0,0,0]])\n",
    "```\n",
    "\n",
    "The other challenge was to compute the process noise matrix Q. We assumed the noises to be independent so the non-diagonal terms had to be zero. For the diagonal terms we found our answer here: https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/07-Kalman-Filter-Math.ipynb. We don't really understand the 'why' of the math behind it but the kalman converged with this Q matrix so we are happy with it (and it did not work with other tries)\n",
    "The final implementation of the Q matrix was this: \n",
    "```python\n",
    "#compute Q according to dt \n",
    "        self.kf_pos.Q = np.array([\n",
    "        [1/4 * noise**2 * dt**4, 0, 0, 0, 0, 0],\n",
    "        [0, 1/4 * noise**2 * dt**4, 0, 0, 0, 0],\n",
    "        [0, 0, noise**2 * dt**2, 0, 0, 0],\n",
    "        [0, 0, 0, noise**2 * dt**2, 0, 0],\n",
    "        [0, 0, 0, 0, noise**2, 0],\n",
    "        [0, 0, 0, 0, 0, noise**2]])\n",
    "```\n",
    "In the end we had to compute the noise of each measurement. We assumed it to be white noise for all measurement and to be equivalent for the x and y part. The process to calculate the noise will be detailled below. For the implementation of the measurement noise matrix we used diagonal matrix with the covariance of the measurement: \n",
    "\n",
    "```python\n",
    "#for acceleration\n",
    "self.kf_pos.R = (self.ACCEL_NOISE**2)*np.eye(2)\n",
    "#for velocity\n",
    "self.kf_pos.R = (self.VEL_NOISE**2)*np.eye(2)\n",
    "#for position\n",
    "self.kf_pos.R = (self.POS_NOISE**2)*np.eye(2)\n",
    "```\n",
    "We also had to initalize our start variable and the trust we have in it and then we were good to go! Our kalman loop looks like this (here for the acceleration measurement only but the idea doesnt change for others measurements)\n",
    "```python \n",
    "#call this line when you want to update the accelerometer measurement\n",
    "kf_pos.update_acceleration([accx,accy],current_time)\n",
    "\n",
    "def update_acceleration(self,data,time):\n",
    "    \n",
    "        # calculate time since last measurement and update it\n",
    "        dt = time- self.time_pos\n",
    "        self.time_pos = time\n",
    "\n",
    "        #get current rotation from other kalman\n",
    "        rotation = self.kf_rot.x.T[0]\n",
    "\n",
    "        # Transform body frame to local frame\n",
    "        data = change_frame(data, rotation)\n",
    "\n",
    "        # Save measurement for plotting\n",
    "        self.accel_measurement.append(data)\n",
    "\n",
    "        # Update kf parameters to accept accel measurement\n",
    "        self.kf_pos.H = np.array([[0,0,0,0,1,0],\n",
    "                                  [0,0,0,0,0,1]])\n",
    "        self.kf_pos.R = (self.ACCEL_NOISE**2)*np.eye(2)\n",
    "\n",
    "        #Update kalman\n",
    "        self._compute_kf_pos(data,dt)\n",
    "\n",
    "\n",
    "# Same for velocity, position and acceleration measurement\n",
    "# Update the F matrix, Q matrix and update the measurement for the position kalman\n",
    "def _compute_kf_pos(self,data, dt):\n",
    "\n",
    "    # get accel_noise for process noise matrix\n",
    "    noise = self.ACCEL_NOISE # most dominant noise\n",
    "\n",
    "    # compute F according to dt\n",
    "    self.kf_pos.F = np.array([[1,0,dt,0,0.5*dt**2,0],\n",
    "                    [0,1,0,dt,0,0.5*dt**2],\n",
    "                    [0,0,1,0,dt,0],\n",
    "                    [0,0,0,1,0,dt],\n",
    "                    [0,0,0,0,1,0],\n",
    "                    [0,0,0,0,0,1]])\n",
    "    \n",
    "    # compute Q according to dt \n",
    "    self.kf_pos.Q = np.array([\n",
    "    [1/4 * noise**2 * dt**4, 0, 0, 0, 0, 0],\n",
    "    [0, 1/4 * noise**2 * dt**4, 0, 0, 0, 0],\n",
    "    [0, 0, noise**2 * dt**2, 0, 0, 0],\n",
    "    [0, 0, 0, noise**2 * dt**2, 0, 0],\n",
    "    [0, 0, 0, 0, noise**2, 0],\n",
    "    [0, 0, 0, 0, 0, noise**2]])\n",
    "\n",
    "    #predict and update kalman\n",
    "    self.kf_pos.predict()\n",
    "    self.kf_pos.update(data)\n",
    "```\n",
    "## Kalman for rotation \n",
    "\n",
    "The kalman for rotation is very similar to the kf_pos except that the measurements differ ( and there is not any frame change). We used as state variable (and measurement also) the heading (from the camera) and the heading rate change (from the wheel speed difference). As the implementation is easier than kf_pos we will not review his full implementation as we can just adapt the steps presented above. \n",
    "\n",
    "## Noise processing and data acquisition\n",
    "\n",
    "For the noise calculation and the measurement equivalence we did the following: \n",
    "Position x and position y : Measurement: from the camera. Noise: make the robot stand still with the camera looking at it. Save the camera measurements of the position and extract the covariance. \n",
    "Velocity x and Velocity y : Measurement: fix identique speed for both wheel. Measure the time to cover a known distance and deduce a linear speed for all motor input. Always output the average of the two wheels and make it go through the rotation matrix. Noise: We fine tuned it using the position from the camera as a ground truth\n",
    "Acceleration x and acceleration y: Measurement: from the accelerometer, we changed the value taking the gravity as a reference. Npise: as the accelerometer were giving stable values when the thymio was stopped we use the 9.81/21(equivalent of gravity for accelerometer) as a value. We increased it by 10 later on since it seemed very inaccurate (accelerometers were not precise enough)\n",
    "Heading change (spin): Measurement: from the wheel. We gave an opposite speed to the 2 wheels than we calculated the time to make 10 turn around itself and calculated the spin in rad/s. From this we computed a linear relation between the spin and the wheel speed difference. Noise: We fined tuned it using the heading from the camera as a ground truth.\n",
    "Heading: Measurement: from the camera. Noise: make the robot stand still with the camera looking at it. Save the camera measurements of the heading and extract the covariance.\n",
    "\n",
    "In the end our noises were declared in the kalman class with those values:\n",
    "\n",
    "``` python\n",
    " ACCEL_NOISE = 10*9.81/23\n",
    "VEL_NOISE = 0.001\n",
    "ROT_NOISE = 0.005\n",
    "POS_NOISE = 0.005\n",
    "SPIN_NOISE = 0.1\n",
    "```\n",
    "\n",
    "\n",
    "## Simulation of the kalman\n",
    "\n",
    "All the simulation of the kalman have been made in kalman.ipynb. We created artificial sensor data and we added white noise to it. We also tested the class we create in test_kalman_class.ipynb (but note that since the noise value are not accurate the result don't fit the curve perfectly but it still is a good example on how to use the Kalman class with rotation and acceleration data). In kalman.ipynb we simulated acceleration measurement and position measurement then stopped position measurement to only rely on accelerometer data. All measurements are in local frame.\n",
    "\n",
    "\n",
    "<img src=\"images/kalman_simulation_position.png\" alt=\"Results for the position, the initial position starts at (25,0)\" width=\"400\"/>\n",
    "\n",
    "Legend: Results for the position, the initial position starts at (25,0). We can see that despite having no GPS data the position estimation fits really well the ground truth but drift slowly away from it. The estimation converges quite quickly to the ground truth position in the beginning\n",
    "\n",
    "<img src=\"images/kalman_simulation_speed.png\" alt=\"Results for the speed\" width=\"400\"/>\n",
    "\n",
    "Legend: Results for the speed. We can see that it matches the ground truth but it takes somes times to converge when the speed changes. \n",
    "\n",
    "<img src=\"images/kalman_simulation_acceleration.png\" alt=\"Results for the acceleration\" width=\"400\"/>\n",
    "\n",
    "Legend: Results for the acceleration. We can see that we start hitting the limit of the kalman since the shift becomes more important. The results are still accurate\n",
    "\n",
    "\n",
    "## Real application of the kalman\n",
    "\n",
    "Now it was time to test our kalman in the robot. We made the robot follow a path, hid the camera for a bit and saw what is gave us. It is important to notice that make the robot working with bluetooth and the sensor values were a bit shifted over time. \n",
    "\n",
    "<img src=\"images/Kalman_setup.png\" alt=\"Kalman results\" width=\"400\"/>\n",
    "\n",
    "Legend: Picture of the kalman path\n",
    "\n",
    "<img src=\"images/Kalman_position.png\" alt=\"Kalman results\" width=\"1100\"/>\n",
    "\n",
    "Legend: Kalman position vs Camera measurement. The robot starts on the bottom left. We can see that the kalman estimates the path perfectly when there is camera measurement. When there is not we can see that the inertial navigation does the job even though it drifts a little over time.The results tend to differ from one try to another (espcially when it is connected via cable or bluetooth). In general, the inertial navigation allows the thymio to go across the whole board (long side) with 2-3 turn with a +- good approximation on the position\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start the client and wait for a lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
